#+LATEX_HEADER: \usepackage{xeCJK}
#+LATEX_HEADER: \setCJKmainfont{STKaiti}
#+OPTIONS: \n:t ^:nil
#+TODO: TODO(t) STARTED(s) WAITING(w) | DONE(d) CANCELED(c)
* Linux的内存管理
linux的内存是比较复杂和轻巧的，要考虑的问题很多，我们在3503中和us282f中使用的方式，都可以从linux的解决方案中找到影子，以目前在项目中使用的linux 3.10的内存为例（linux最新的内存管理系统还没看过），简单描述下linux的内存管理系统，再讨论其他RTOS的内存管理系统
** 物理内存管理
+ 4k内存页
  linux最基本的内存管理是按照内存页来管理的， 把全部物理内存按照4k大小（可配置，一般都是4k）来划分出来。
+ 伙伴算法
  多个4K内存页的分配使用的内存分配方式是伙伴算法（buddy）。
  整个4k的连续空间，在Linux中会被划分为多个连续的块（比如8M）， 使用buddy算法的时候，比如要分配一个1M大小的连续空间， 会先把8M拆分成2个4M， 把其中一个4M拆分成2个2M， 再把其中的一个2M拆分成两个1M， 然后拿其中的一个1M满足分配。 每一个这样的拆分出来的两块就成为一对伙伴。
  在释放这个1M的块时， 如果对应的伙伴是空闲的， 那么就会合并成一个更大的块， 更大的块的伙伴如果是空闲的， 那么会继续合并下去。
  伙伴系统的好处就是相对没那么容易碎片化。缺点是可能会有内存浪费。
+ 内存分配
  + 应用层
    应用不同进程都自己的页表，因此按照物理内存单页分配的方式，通过进程的页表映射成连续虚拟空间就可以了。应用内存的分配只需要分配单个的4k页就能满足要求了
    同时，分配给应用的物理内存，内核随时都可以通过修改进程页表的方式来收回（代码段只读内存）或者移动（数据等读写内存）。而这个行为完全对应用程序透明。
  + 内核和驱动程序
    linux是一个巨内核的系统，内核本身和驱动程序都是在同一个地址空间内，因此分配的数据物理内存不能移动。代码部分也不能缺页，都是常驻在内存中的。
    在需要的内存小于4k的时候，任意单个4k页就可以满足， 但如果需要的内存大于4k， 则必须分配物理上连续的内存页，这个就必须要在整个内存空间中整理出来连续的段才可以满足内存分配

    主要的问题就是内存片问题，在系统运行较长的时候，很难整理出连续的物理内存页。在7029平板方案中，有遇到过问题，1G内存，usb传输申请一个连续的32kbyte的buffer都申请不出来。

    碎片问题的避免在linux中有几个办法：
    + 提前申请，占住不放
      避免重复分配和释放。 但有些问题不适合这样解决。同时也会稍微的降低一下内存利用率
    + 使用vmalloc
      分配的时候仍然分配物理不连续的内存，为分配的内存创建新的内存页表来映射成连续内存
      但这种方法只能用在只被cpu访问的内存上，不能被dma访问，另外一方面，32bit内核的这个内存映射区域是比较少的
    + CMA的方式
      以性能为代价，解决在内核中分配连续物理内存的方式
*** 内存碎片的缓解和解决
**** 内存碎片的缓解
linux在CMA之前已经做了一些防止内存碎片化的动作， 主要如下：
+ 划分成多个迁移类型(MIGRATE_TYPES)来适配不同的分配需求
    把内存区域划分成多个MIGRATE_TYPES的区域， 比如MIGRATE_UNMOVABLE, MIGRATE_RECLAIMABLE,  MIGRATE_MOVABLE, MIGRATE_RESERVE等，迁移类型按照8M（假设max order=11）对齐。
  + MIGRATE_RESERVE是最后的预备队，用于紧急内存分配。
  + MIGRATE_RECLAIMABLE用于可回收的内存分配，
  + MIGRATE_UNMOVABLE是通常的不可以移动的内存分配，
  + MIGRATE_MOVABLE用于可移动的内存分配，
    根据内存分配的使用者需求，确定在那个区域中进行分配，这样可以减少单页的内存分配打断连续的内存区域的概率。
+ 内存回收尽可能减少碎片
  linux系统为了更好的性能，会尽可能把空闲的内存用于缓存，当系统空闲的内存低于一定水平线（watermark）后就会进行内存扫描，在扫描中会尽可能回收出连续的区域
  + 对可以回收的内存进行回收， 回收的同时会把连续的小块区域合并成大块区域
  + 对造成连续区域碎片的可以移动的内存页，迁移这些页内的内容，重新合并成一个连续区域
+ 迁移类型之间的fallback来解决内存复用
  当一个迁移类型中的内存页不够分配的时候，就会fallback到其他迁移类型中，会根据不同的分配类型确定fallback的顺序。
  fallback相当于借用，每次借用的时候都是按照一个max_order_block来借用的， 比如我们配置的这个值是11，那么每次借用就是2048*4K=8M大小。借用的时候归还也是整块归还。
+ oom Killer
  当内存分配不允许失败，同时内存由于碎片分配不出来时，会执行oom（out of memory）过程，据一些规则，挑选某些进程，直接杀死这些进程来释放内存

即使采用了以上种种缓解内存碎片的办法，仍然会遇到因为内存碎片导致整个系统几乎不能用的情况。
**** CMA（continuous memory allocation）
在kernel 3.4以后开始引入了CMA内存分配的方式，主要是用来满足大块的连续内存分配，原理如下：
+ 设置一个新的迁移类型MIGRATE_CMA
  系统使用的内存，只有允许移动的系统内存才能在CMA中分配，其他不能移动的内存分配也不能迁移到CMA这个区域。
+ 使用dma_alloc_coherent来分配物理连续内存
  当需要连续物理内存的时候，调用dma_alloc_coherent会把选定区域的内存页迁移出去，形成连续物理内存。

通过这种方式可以满足大部分的驱动和内核的连续物理内存要求，并在驱动不使用cma内存的时候，又可以用于可移动的系统内存分配，提供内存利用率。
即使这样，如果CMA区域内按照CMA的分配方式也可以出现碎片，这种就只能通过把CMA区域设定得足够大来解决。

** slab分配器
根据前面的讨论，对小于4k的内存分配，简单的一个单页分配就可以解决问题，没有碎片的问题，但如果仅仅为了分配几个字节就使用一个页，太浪费了，所以就出现了slab分配器。

通过kmem_cache_create创建一个slab高速缓存，创建的时候会指定在该slab中的object的大小，初始的object的个数。实现就是使用多个不连续的4k的页，每一个4k的页满足很多个对象的分配（4096/object大小），这样可以提高内存的利用率。

在kernel的不同子系统中都有使用各种大小的高速缓存，高速缓存的好处有：
+ 没有碎片问题
  每个高速缓存可以简单理解为一个可伸缩的数组，每一项都是固定大小的
+ 分配快速
  内存的分配不涉及到kernel的内存分配子系统，后者是相当复杂和缓慢的
+ 内存利用率高
  几乎没有字节浪费
+ cache line优化
  使用cacheline着色等技术，优化cache访问
+ 可以动态伸缩
  在使用的对象不多的时候，可以把内存还给系统。分配空间不够用的时候，会从系统中再申请新的4k页。

除了各个子系统的专用的高速缓存外， linux系统中还提供了通用的高速缓存用于内存分配，通用的slab中的object的大小分别是， 16，32，64，128，256 一直到1024大小。
* RTOS中的动态内存分配
** 282f的动态内存分配
目前合肥的需求是提供一个不需要支持wifi，和仅仅需要支持蓝牙的开发平台，采用的方法是保留系统最基本的框架（去掉wifi，解码，播放，录音，网络等）， 移植了282f的动态内存管理机制，能提供出来的最大的内存有98K。

2828f中使用内存策略简单如下：
+ 各个功能模块，都尽量使用动态内存分配的malloc和free来分配内存
+ 尽量不使用静态内存，或slab的方式，把可用的内存尽可能的都留给heap
+ 使用防碎片的heap管理算法
  把可以使用的内存分为2k页大小的block， 每一个进程使用内存时，会先从系统中分配一个2k的页，在每一个2k页内使用伙伴系统来管理内存。2k只有全部空闲的话才会还给系统。
**** 内存碎片问题
  通用的动态内存管理算法最大的问题就是碎片的问题，linux算是为放置碎片做了更多的工作的，同时还有mmu，可以移动内存，仍然避免不了碎片问题， 只有使用cma之后，才解决了驱动程序和内核需要的碎片问题。
  282f的内存管理机制与linux相比，更不容易解决问题，主要如下：
  + 没有mmu
    因此不能做通过移动内存的方式来合并素片
  + 防碎片措施少得多
    有更多的碎片的可能
  + 可管理的内存少太多
    管理的内存越多，遇到碎片的可能就越少

  282f的算法很类似前面讨论的基本的linux对4k页的管理的方式的方法，  linux中每8M（max_block_order=11的时候）是一个block， 其中8M内就是使用伙伴系统管理的。
  在这里我们把linux的4K的页当做282f中的一个字节。8M刚好是2K个页。可以相当于282f的2k的block。

  根据以前做平板的经验可以知道，在没有使用CMA内存之前， 在1G内存（相当于256K个页）的情况下，最后分配一个32K大小的页（相当于8个页），都分配不出来。这个还是在linux还有更多的防止碎片化的机制（不同的迁移类型来隔离分配，移动内存页来减少碎片）的情况，如果在同样的内存压力情况下，282f的碎片问题应该更难解决。

  282f在实际的使用中没有遇到很多的碎片问题，有两个可能的解释：
  + 总的内存在各个场景下还是相对比较宽裕的，
    不管哪种通用的内存管理系统，在总内存压力不大，分配的size不够碎，动态并发性不高的时候，还是相对不太容易遇到碎片问题的。
  + 或者不同场景下内存使用的时候需要注意特别的顺序。
    专门优化各个应用场景，让应用或系统模块申请内存的方式配合起来，避免碎片出现。
** 3503 系统中的内存使用策略
*** 主分支目前故事机方案的内存使用情况
| module name             | data size |
| actions应用框架核心服务 |    31,102 |
| 应用框架开源部分        |    14, 753 |
| 网络核心协议栈          |    24,441 |
| wifi驱动相关栈             |     8,995 |
| 内核                    |     6,632 |
| 设备驱动                |     3,999 |
| 故事机应用              |     3,032 |

说明：
+ 解码库部分  53k
  不同编码格式和解码格式是共用内存的， 相互overlay，最大的overy是53K
+ 系统框架和核心服务  31K
  主要是两部分核心服务使用的heap和stack，启动heap 17k， stack 12k左右， heap中还包含了wifi驱动使用的动态内存。
+ 应用开源部分 14K
  提供给用用程序使用的堆， 和系统核心服务使用的heap分开管理
+ 网络协议栈部分 24K
  主要是网络使用的buffer， 总共10个， 每个1.6k，以及其他的一些小buffer，
+ wifi驱动  9k
  wifi固件这部分主要是驱动使用的静态内存部分，主要是一个比较大的stack。wifi驱动使用动态内存都在应用框架的heak中分配
+ 内核和其他驱动 10K
*** zephyr中的内存使用策略
在zephyr中，内存使用的思路如下：
+ 静态或全局变量
  对重要的数据结构，使用全局变量的方式，比如大部分的内核和设备驱动，
+ 静态的pool
  大量的同一类型和的的数据结构或同样大小的缓冲区，使用类似linux的高速缓存slab结构，在zephyr中称为pool，但与linux的高速缓存不同的是，zephyr中的slab底层没有页系统支持，所以是不可以伸缩的。
  这部分主要是网络协议栈中使用的网络缓冲区，以及相应的数据结构
+ 通用heap
  zephyr中提供了一种heap的管理算法，就是把一整块的内存区域使用伙伴算法来管理。
  尽管zephyr提供了这种方式，但在整个的系统代码中并没有使用。
+ 3503增加的heap管理机制
  由于有一些需求，使用静态变量或pool都不能满足，而必须要使用heap的方式，主要有：
  + wifi驱动在运行的时候需要经常的动态分配不同大小的内存，需要10多K左右
  + 网络上层协议的解析，比如jason格式的parse，需要经常的分配和释放内存
  + 应用各个互斥场景切换，比如播放，录音，百科文档，语音留言等。

  为了充分利用内存就需要使用heap的方式，在3503中增加一种heap的管理方式，暂且命名为slab_heap吧。

  slab_heap使用的方法类似linux的通用高速缓存的方式，会提供32，64，128， 256，512，1024..等各种size的pool。每个pool根据实际的需要配置一个个数。

  与linux通用的高速缓存不同的有两点：各个pool的size不一定是2的整数幂，每个pool支持有限的伸缩。

  在3503的发布版本上，整个系统只提供了一个slab_heap，凡是需要动态内存的地方都这个heap，在内部的开发分支上，把不开源的系统服务和wifi使用一个slab heap， 然后所有开源部分的应用使用另外一个slab heap。前者为17k， 后者为14k。分开的好处就是应用的内存使用永远不会影响到系统。
**** 内存利用率问题
使用slab heap的有点是没有内存碎片的问题， 缺点是如果在多场景下提高内存利用率的问题。

举例如下：
目前我们需要同时支持蓝牙和wifi的功能，这两部分都属于不开源的部分，都使用系统的slab heap。但两者的使用方式如下：
wif音频运行时i需要的内存是 10个 512*3 的buffer， 蓝牙音频运行时需要的是30个512字节的buffer，wifi和蓝牙驱动都需要同时存在。
如果内存管理算法做得足够好，那么理论上来说15K的内存就够了。而使用slab_heap的方式，可能就需要25K才够。主要原因是10个512*3的buffer，并不能有效的作为30个512字节的buffer来使用。

可能的改进：
如果这样的情况出现较多，可以考虑进一步增加slab heap的功能和feature，在slab heap之下再增加linux的页管理的机制。最终实现不同size的pool可以真正的动态伸缩，通过底层的页来在不同的pool中复用内存。
这样的修改除了增加复杂性外，需要根据sdk的实际情况来权衡一些要考虑的问题，从目前sdk的实际情况看，利用率是ok的， 不增加是更好的选择，后续整合蓝牙音频后，再具体情况看一下
要考虑的问题有：
+ 底层页的大小
  页至少要能够满足一个最大的object的大小， 比如2k。
  每一个pool即使用不到2k大小， 也会占用一个页， 比如32byte的object， 如果数量不多可能就会浪费一些内存。
+ 回收页的机制
  如何，何时回收，缩减某些pool的size，以腾出内存给需要的pool。
*** broadcom wiced BT的动态内存管理
broadcom的wiced bt是一个蓝牙的开发平台，同时支持BR EDR  BLE以及各种profile。
| Technology            | Bluetooth (BR + EDR + BLE)                        |
| Bluetooth Spec.       | Bluetooth 4.2                                     |
| RX Sensitivity        | -93.5 dBm                                         |
| Max. TX Power         | 12 dBm (Programmable TX Power)                    |
| Power-Class           | Class 1, Class 2                                  |
| CPU Core              | ARM Cortex M3                                     |
| Flash/EEPROM          | Ext. Flash/EEPROM support                         |
| Internal              | 848 KB ROM                                        |
| SRAM                  | 352 KB                                            |
| Coexistence Interface | GCI SECI (2-wire)                                 |
| Serial Interfaces     | 2 UART, 2 SPI, I2C, PCM, I2S                      |
| ADC                   | 10-bit @ 100 KHz (Static) 13-bit @ 16 KHz (Audio) |
| GPIOs                 | Up to 24                                          |

在每一个应用的开始会调用wiced_bt_stack_init来初始化， 该函数的第三个参数就是sdk的buffer的配置， 针对不同的使用场景，有不同的buffer配置， 比如对a2dp协议的例子：
#+BEGIN_SRC C
 * Configure buffer pools used by the stack  according to application's requirement
 *
 * Pools must be ordered in increasing buf_size.
 * If a pool runs out of buffers, the next  pool will be used
const wiced_bt_cfg_buf_pool_t a2dp_sink_cfg_buf_pools[] =
{
/*  { buf_size, buf_count } */
    { 64,       12  },      /* Small Buffer Pool */
    { 272,      6   },      /* Medium Buffer Pool (used for HCI & RFCOMM control messages, min recommended size is 360) */
    { 1056,     6   },      /* Large Buffer Pool  (used for HCI ACL messages) */
    { 1056,     0   },      /* Extra Large Buffer Pool - Used for avdt media packets and miscellaneous (if not needed, set buf_count to 0) */
};
#+END_SRC
在这里可以看出，使用了几个固定大小的pool分别用于hci， avdtp协议的动态内存分配， 这些协议在wiced bt平台是不开源的。

而对开源部分的内存使用，wiced bt中提供了多种内存管理算法以供选择。有基于pool的方式的， 也有基于通用的heap管理的方式的。
*** aihora AB1520S耳机和音箱方案

洛达的AB1520s方案的ram总共32k， 其中13k左右是全局变量使用，剩下的19k用作动态分配的heap， 内存堆管理使用多个预先配置的pool的方式，

一个典型的具体配置如下：
| pool名称             | 大小（项数x大小） |
| CallArrayEntries     | 16 * 4            |
| TimerArrayEntries    | 50 * 4            |
| OSMEM1ArrayEnties    | 40 *50            |
| OSMEM2SmallTxEntries | 9 * 702           |
| OSMEM2TinyRxEntries  | 3 * 62            |
| OSMEM2SmallRxEntries | 3 * 1100          |
| OSMEM2LargeRxEntries | 2 * 1100          |
| UartDmaRxBufSize     | 380               |
** FreeRTOS中的heap管理
FreeRTOS提供了5种HEAP分配方案。各应用可以按照自己的实际需求来选择合适的HEAP实现方式。HEAP实现代码位于Source/Portable/MemMang目录下。
*** 方案 1 - heap_1.c
这是所有方案里最简单的。当内存分配后，它不允许释放内存，但除了这点，它适合于大量的应用。若应用永远不会删除任务或队列（永远不会调用 vTaskDelete () 或 vQueueDelete ()），则可使用。
heap_1.c 适用于很多在内核启动前即创建了所有任务和队列的小实时系统。
*** 方案 2 - heap_2.c
此方案使用了最佳适用算法，与方案1不同，它允许释放之前分配的块。然而，它不会将相邻的自由块合并为一个大块。
heap_2.c 适合于很多必须动态创建任务的小实时系统。
*** 方案 3 - heap_3.c
它仅是标准 malloc() 和 free() 函数的封装。它可确保线程安全。此方案特点为：
• 需要链接器建立堆，编译器库提供 malloc() 和 free() 的实现。
• 它不是确定性的。
• 可能会大幅增加内核代码量。
*** 方案 4 - heap_4.c
此方案使用了首先适用算法，与方案 2 不同，它不会将相邻的自由内存块合并为一个大块（它不包含合并算法）。
*** 方案 5 - heap_5.c
它允许程序设置多个非连续内存堆，比如需要快速访问的内存堆设置在片内RAM，稍微慢速访问的内存堆设置在外部RAM。每个内存堆的起始地址和大小由应用程序设计者定义。

* 建议的主要的设计策略
RTOS的系统，受限于实际可用的资源，需要针对最大场景对内存资源做一些大的规划，不能太指望通用的heap管理策略。
+ RTOS需要减少动态内存的使用方式
  分多个层次：
  适合使用全局数据的使用全局数据
  适合使用专用的高速缓存pool的使用专用的pool
  必须使用动态内存的才使用动态内存，而不是都尽可能的都是用动态内存。
+ 平台整合功能的动态内存使用方式需要使用可预测的管理方式
  比如3503整合的wifi 音频相关的功能，后续会继续整合的蓝牙音频相关功能。
  这部分的内存使用应当使用可以避免内存碎片的管理方式，内存碎片的最大的问题就是不可以预测性。
  这部分的动态内存使用方式最好和应用的动态内存使用分开。分开的好处是容易做针对性的优化来提高使用率，以及不受应用内存分配算法的影响。
+ 可以整合多种动态内存算法，提供给应用层使用
  由于平台上的应用的需求是千变万化的，可以也应当考虑提供多种算法供实际应用选择，同时也需要考虑能方便客户整合自己的内存管理算法。

  举两个实际的例子：
  + 合肥客户
    只需要蓝牙的controller功能，甚至都不需要协议栈。
    这种情况下，裁剪掉其他功能后，可以有接近100k的内存，主要的代码都是客户自己的代码， 提供一个类似282f的算法那也是可以的， 遇到碎片问题客户应该可以自行解决。
    也可以由客户自己整合内存管理算法。
  + 指纹锁
    只需要蓝牙BLE的功能，
    甚至不需要使用内存分配算法， 整个算法是自己管理内存的。

* RTOS选型
** RTOS对比

目前主要的RTOS的操作系统可以参见下面的链接
https://www.osrtos.com
http://www.linuxidc.com/Linux/2016-11/137178.htm

主要考察了如下几个OS：
|              | mbed OS      | FreeRTOS                   | Zephyr                          | nuttx      |
| 资源占用     | 较小         | 小                         | 小                              | 较大       |
| 许可证       | apache 2.0   | LGPL                       | Apache 2.0                      | bsd        |
| 社区         | 主要arm大厂  | 个人开发者                 | 个人，intel，nordic以及linaro等 | 基本无     |
| 无线协议支持 | 以太网       | 以太网                     | 15.4，蓝牙，以太网              | 以太网     |
| 组件         | 有不开源部分 | 有不开源部分，且许可证不同 | 开源                            | 开源       |
| 跨平台       | arm          | arm mips                   | arm 可增加mips                  | arm mips   |
| 可配置性     | 一般         | 不同组件不同               | 好    Kconfig                   | 好 Kconfig |
| 组件丰富程度 | 好           | 不好                       | 较好                            | 最好       |
| 开发便利性   | 最好         | 不相关                     | gcc环境，后续会支持keil，iar等  | gcc环境    |
| soc hal      | 有           | 无                         | 有                              | 有         |
| 文档化       | 好           | 一般                       | 好                              | 差         |

也同时也评估过其他的OS ，比如rt-thread  contiki等。

选择主要考虑如下方面：
+ 资源占用
  从资源占用看， 这4个os都基本可以满足要去， 除了nuttx稍大一些外
+ 许可证
  bsd，和apache的许可证是最适合商用的， 可以根据自己需要闭源和开源都没有限制。
  FreeRTOS本身是LGPL的，相对还好，主要问题是， FreeRTOS之上的组件的都是不同的license，有一些不开源的同时，还不是免费的。
  如果选择FreeRTOS的话，比较好用的上层组件只有lwip这个tcp/ip的协议栈，这个也是最常看到的组合，其他比较多的组件有license和开源的问题。
+ 社区支持
  之所以选择一个新的操作系统来，主要还是为了这一点，要充分利用开源和社区的力量，尽量避免独力发展一套私有系统。如果重点不是考虑这一点，继续使用ucos也是一个选择。
  + nuttx
    从社区支持看， nuttx基本都是由主要的开发者一个人维护的，是最大的问题
  + FreeRTOS
    FreeRTOS采用的比较多，尤其是FreeRTOS + lwip的组合，基本上每一个wifi vendor都有提供这样组合的示例。但FreeRTOS的问题也很明显，基本只有一个核心可以用。其他部分基本都要自己完成。
  + mbed
    mbeded主要是arm在推动，各个arm芯片的供应商支持mbed的方式，主要是把自己的芯片和开发板适配到mbed平台。
    mbed平台的其他各部分组件的整合是arm和社区推动的，但特别的松散，但评估的时候看，各个组件的质量不同，整合起来的质量和稳定性也不尽如意。同时，有一些组件还包含二进制的部分
    5601的ic，可以考虑后续适配到mbed上
  + zephyr
    license是apache的， 同时整合进来的组件都是apache或bsd的license，也没有不开源的部分，目前已经整理进来很丰富的组件了， 比如tcp/ip， ble，zigbee， 文件系统，mtls等。
    是Linux Foundation托管的项目，采用了类linux内核的社区模式，个人开发者也可以参与其中，同时也有比较多的大公司主导推动，intel，synopsis  nxp nordic 等公司。
    目前zephyr的发展和迭代都非常快，bug修复也很快。像BLE的mesh在标准发布没有多久就可以支持了。https://www.linux.com/news/event/open-source-summit-na/2017/4/building-wearable-device-zephyr
+ 无线协议支持
  在评估了前面几条后，zephyr基本上就是唯一选择了。如果是arm soc，可以支持mbed平台而已。并不会作为主要的软件基线。
  选择zephyr还要一个重要的考虑就是，可以整合蓝牙音频，以及蓝牙BLE和WIFI相关的到同一个平台中。
  这样可以让多颗IC使用同一个软件平台。
+ 可配置性支持
  zephyr和nuttx都使用了类似linux的Kcofig系统，比较方便配置需要的功能，这个虽然不是至关重要的功能，也是很需要的一个功能，方便后续再一个sdk中逐渐整合越来越丰富的功能，但又能很容易的去掉不要的功能。

  两个例子：
  支持基本蓝牙功能后，合肥基于wifi故事机的版本， 经过简单的配置和一些修改就整合出来一个蓝牙的版本。
  蓝牙指纹锁需要提供一个BLE的版本，这个通过简单配置，较少的工作就可以提供一个BLE版本的功能。
+ 其他方面
  剩下的其他方面的影响并不致命，就算遇上问题也是可以克服的， 比如：
  + 音频解码
    就算linux这样的系统也需要一定的整合工作， 对RTOS需要自己整合
  + GUI
    zephyr并没有整个显示和GUI，估计将来也不会整合GUI进来， 这个工作如果需要可以由我们自己完成
  + API不成熟
    由于zephyr整个项目还处于早期，所以，经常还会出现api的大幅变化，这个需要我们在同步跟踪新版本的时候，有所取舍同时也需要做好测试
  + bug较多
    从目前看，kernel本身没有遇到太多问题，其他网络等组件，还不够成熟，甚者有一些低级错误，但这个影响还好，一来是zephyr自身修复较快，二来，小系统我们自己也是可以掌握和debug的，
** zephyr是否适合做复杂系统
系统的复杂性主要是由几个方面带来的
+ 系统的主要功能，
+ 功能之间的主要关系和协作，
+ 所受到的环境或资源限制，
+ 要达到的质量和性能要求。
从这几个方面来说，os核心的选择主要影响后两者。 os+组件的选择会同时影响这4个方面。当然，最重要的影响还是产品的规格。

从复杂系统角度而言，用linux是最好的选择。

但就RTOS而言，从考察的各个系统来说：
nuttx可以认为是linux的瘦身版，在稍微放宽资源限制的时候，是最适合的， os核心的服务很丰富，也有丰富的组件，但由于生态的原因不能选择。
FreeRTOS基本上可用的就是os+lwip，其他部分都需要自己构建
mbed和zephyr差不多，但mbed的os本身是有一些问题的，组件同样有一些问题。

可以拿我们熟悉的ucos来做一个对比， 我们使用的ucos也只使用一个核心，其他部分全是我们自己构建的，就单纯对比ucos和zephyr的核心来说， zephyr相对uc的核心提供了更多的操作系统相关的服务，我们使用uc可以做到的复杂性，使用zephyr一定是可以做的。
zephyr系统除了核心外，我们还是复用了很多其他的组件的，只是没有的组件需要我们自己（或其他第三方）构建，相对uc系统而言，已经大大的减少了工作量了， 因而会更容易。

因此，使用zephyr构建复杂系统不应该会有很大的不足。

总的来说:
zephyr算一个复杂度中等的os， 比uc提供的功能丰富一些。其实就目前看对BLE only的都稍微重了一点。
contiki和mbed os 是更轻量级的，洛达的os是更轻量级的， 完成蓝牙音频的功能也没有问题
nuttx是更重量级的， 基本算瘦身的linux。
